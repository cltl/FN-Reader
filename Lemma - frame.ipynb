{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemma to frame relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_utils\n",
    "from collections import defaultdict, Counter\n",
    "import pandas\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = stats_utils.load_framenet(version='1.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_pos = True \n",
    "\n",
    "lemma2frames = defaultdict(set)\n",
    "frame2lemmas = defaultdict(set)\n",
    "\n",
    "for frame in fn.frames():\n",
    "    frame_label = frame.name\n",
    "    for lu in frame.lexUnit.keys():\n",
    "        lemma, pos = lu.split('.')\n",
    "        \n",
    "        if with_pos:\n",
    "            lemma2frames[(lemma, pos)].add(frame_label)\n",
    "            frame2lemmas[frame_label].add((lemma, pos))\n",
    "        else:\n",
    "            lemma2frames[lemma].add(frame_label)\n",
    "            frame2lemmas[frame_label].add(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_polysemy = [len(value) for value in lemma2frames.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hit', 'v') {'Cause_motion', 'Experience_bodily_harm', 'Eventive_affecting', 'Hit_or_miss', 'Impact', 'Cognitive_impact', 'Attack', 'Cause_harm', 'Arriving', 'Cause_impact', 'Hit_target'}\n",
      "('strike', 'v') {'Coming_to_believe', 'Erasing', 'Eventive_affecting', 'Impact', 'Cognitive_impact', 'Attack', 'Cause_harm', 'Cause_impact', 'Light_movement', 'Political_actions', 'Be_in_agreement_on_action'}\n"
     ]
    }
   ],
   "source": [
    "for lemma, frames in lemma2frames.items():\n",
    "    if len(frames) == 11:\n",
    "        print(lemma, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(fn_polysemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10462 1.297266297075129\n"
     ]
    }
   ],
   "source": [
    "average_polysemy = sum(fn_polysemy) / len(fn_polysemy)\n",
    "print(len(lemma2frames), average_polysemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 372,\n",
       "         7: 15,\n",
       "         1: 8475,\n",
       "         4: 125,\n",
       "         2: 1371,\n",
       "         6: 24,\n",
       "         5: 57,\n",
       "         9: 7,\n",
       "         8: 10,\n",
       "         10: 4,\n",
       "         11: 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fn_polysemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = [pos \n",
    "                for lemma, pos in lemma2frames]\n",
    "counts = Counter(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "Part of speech &   Framenet 1.7 &  PropBank 3.1 \\\\\n",
      "\\midrule\n",
      "             n &  44.87\\% (4694) &             - \\\\\n",
      "             v &  31.71\\% (3318) &  100\\% (7,311) \\\\\n",
      "             a &  19.52\\% (2042) &             - \\\\\n",
      "           adv &     2.1\\% (220) &             - \\\\\n",
      "          prep &     0.95\\% (99) &             - \\\\\n",
      "           num &      0.3\\% (31) &             - \\\\\n",
      "          idio &     0.28\\% (29) &             - \\\\\n",
      "          scon &     0.11\\% (12) &             - \\\\\n",
      "           art &      0.06\\% (6) &             - \\\\\n",
      "          intj &      0.05\\% (5) &             - \\\\\n",
      "             c &      0.05\\% (5) &             - \\\\\n",
      "          pron &      0.01\\% (1) &             - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lists_of_lists = []\n",
    "headers = ['Part of speech', 'Framenet 1.7', 'PropBank 3.1']\n",
    "\n",
    "total = sum(counts.values())\n",
    "\n",
    "for pos, freq in sorted(counts.items(), \n",
    "                        key=operator.itemgetter(1),\n",
    "                        reverse=True):\n",
    "    \n",
    "    perc = 100 * (freq / total)\n",
    "    value = f'{round(perc, 2)}% ({freq})'\n",
    "    \n",
    "    if pos == 'v':\n",
    "        one_row = [pos, value, '100% (7,311)']\n",
    "    else:\n",
    "        one_row = [pos, value, '-']\n",
    "        \n",
    "    lists_of_lists.append(one_row)\n",
    "\n",
    "df = pandas.DataFrame(lists_of_lists, columns=headers)\n",
    "print(df.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = [len(value) for value in frame2lemmas.values()]\n",
    "counts = Counter(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rll}\n",
      "\\toprule\n",
      " Variance class & Framenet 1.7 &   PropBank 3.1 \\\\\n",
      "\\midrule\n",
      "              3 &  11.0\\% (118) &              - \\\\\n",
      "              2 &  10.9\\% (117) &              - \\\\\n",
      "              4 &   8.01\\% (86) &              - \\\\\n",
      "              5 &   7.36\\% (79) &              - \\\\\n",
      "              6 &   6.71\\% (72) &              - \\\\\n",
      "              1 &   5.59\\% (60) &  100\\% (10,672) \\\\\n",
      "              7 &   4.75\\% (51) &              - \\\\\n",
      "              8 &   4.29\\% (46) &              - \\\\\n",
      "              9 &   3.73\\% (40) &              - \\\\\n",
      "             10 &   3.63\\% (39) &              - \\\\\n",
      "             12 &   3.26\\% (35) &              - \\\\\n",
      "             11 &    2.8\\% (30) &              - \\\\\n",
      "             13 &    2.7\\% (29) &              - \\\\\n",
      "             14 &   2.52\\% (27) &              - \\\\\n",
      "             16 &   2.14\\% (23) &              - \\\\\n",
      "             15 &   1.49\\% (16) &              - \\\\\n",
      "             18 &   1.21\\% (13) &              - \\\\\n",
      "             26 &   1.21\\% (13) &              - \\\\\n",
      "             17 &   1.12\\% (12) &              - \\\\\n",
      "             25 &   0.93\\% (10) &              - \\\\\n",
      "             23 &   0.93\\% (10) &              - \\\\\n",
      "             20 &    0.84\\% (9) &              - \\\\\n",
      "             22 &    0.75\\% (8) &              - \\\\\n",
      "             21 &    0.75\\% (8) &              - \\\\\n",
      "             24 &    0.65\\% (7) &              - \\\\\n",
      "             19 &    0.56\\% (6) &              - \\\\\n",
      "             38 &    0.56\\% (6) &              - \\\\\n",
      "             39 &    0.56\\% (6) &              - \\\\\n",
      "             28 &    0.47\\% (5) &              - \\\\\n",
      "             31 &    0.47\\% (5) &              - \\\\\n",
      "             42 &    0.37\\% (4) &              - \\\\\n",
      "             29 &    0.37\\% (4) &              - \\\\\n",
      "             27 &    0.37\\% (4) &              - \\\\\n",
      "             32 &    0.37\\% (4) &              - \\\\\n",
      "             69 &    0.28\\% (3) &              - \\\\\n",
      "             46 &    0.28\\% (3) &              - \\\\\n",
      "             36 &    0.28\\% (3) &              - \\\\\n",
      "             41 &    0.28\\% (3) &              - \\\\\n",
      "             59 &    0.28\\% (3) &              - \\\\\n",
      "             35 &    0.28\\% (3) &              - \\\\\n",
      "             33 &    0.28\\% (3) &              - \\\\\n",
      "             67 &    0.19\\% (2) &              - \\\\\n",
      "             77 &    0.19\\% (2) &              - \\\\\n",
      "             56 &    0.19\\% (2) &              - \\\\\n",
      "             40 &    0.19\\% (2) &              - \\\\\n",
      "             55 &    0.19\\% (2) &              - \\\\\n",
      "             49 &    0.19\\% (2) &              - \\\\\n",
      "             63 &    0.19\\% (2) &              - \\\\\n",
      "             80 &    0.19\\% (2) &              - \\\\\n",
      "             71 &    0.19\\% (2) &              - \\\\\n",
      "             47 &    0.19\\% (2) &              - \\\\\n",
      "             37 &    0.19\\% (2) &              - \\\\\n",
      "             95 &    0.09\\% (1) &              - \\\\\n",
      "            104 &    0.09\\% (1) &              - \\\\\n",
      "             72 &    0.09\\% (1) &              - \\\\\n",
      "            163 &    0.09\\% (1) &              - \\\\\n",
      "            119 &    0.09\\% (1) &              - \\\\\n",
      "             53 &    0.09\\% (1) &              - \\\\\n",
      "            182 &    0.09\\% (1) &              - \\\\\n",
      "            136 &    0.09\\% (1) &              - \\\\\n",
      "             73 &    0.09\\% (1) &              - \\\\\n",
      "             51 &    0.09\\% (1) &              - \\\\\n",
      "             84 &    0.09\\% (1) &              - \\\\\n",
      "            106 &    0.09\\% (1) &              - \\\\\n",
      "             64 &    0.09\\% (1) &              - \\\\\n",
      "            105 &    0.09\\% (1) &              - \\\\\n",
      "             66 &    0.09\\% (1) &              - \\\\\n",
      "            115 &    0.09\\% (1) &              - \\\\\n",
      "             45 &    0.09\\% (1) &              - \\\\\n",
      "             94 &    0.09\\% (1) &              - \\\\\n",
      "             61 &    0.09\\% (1) &              - \\\\\n",
      "             58 &    0.09\\% (1) &              - \\\\\n",
      "             50 &    0.09\\% (1) &              - \\\\\n",
      "            152 &    0.09\\% (1) &              - \\\\\n",
      "             52 &    0.09\\% (1) &              - \\\\\n",
      "             87 &    0.09\\% (1) &              - \\\\\n",
      "             79 &    0.09\\% (1) &              - \\\\\n",
      "            179 &    0.09\\% (1) &              - \\\\\n",
      "             92 &    0.09\\% (1) &              - \\\\\n",
      "             48 &    0.09\\% (1) &              - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lists_of_lists = []\n",
    "headers = ['Variance class', 'Framenet 1.7', 'PropBank 3.1']\n",
    "\n",
    "total = sum(counts.values())\n",
    "\n",
    "for freq_class, freq in sorted(counts.items(), \n",
    "                        key=operator.itemgetter(1),\n",
    "                        reverse=True):\n",
    "    \n",
    "    perc = 100 * (freq / total)\n",
    "    value = f'{round(perc, 2)}% ({freq})'\n",
    "    \n",
    "    if freq_class == 1:\n",
    "        one_row = [freq_class, value, '100% (10,672)']\n",
    "    else:\n",
    "        one_row = [freq_class, value, '-']\n",
    "        \n",
    "    lists_of_lists.append(one_row)\n",
    "\n",
    "df = pandas.DataFrame(lists_of_lists, columns=headers)\n",
    "print(df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
